{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-18T09:21:12.359088Z",
     "start_time": "2025-08-18T09:21:05.992688Z"
    }
   },
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from ocr_model import model"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amirreza_Bazmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "228c6f7c1c885af5",
   "metadata": {},
   "source": [
    "# **Some functions about image**"
   ]
  },
  {
   "cell_type": "code",
   "id": "74be0c10a779ba4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T09:21:12.373778Z",
     "start_time": "2025-08-18T09:21:12.367387Z"
    }
   },
   "source": [
    "x_size, y_size = 32, 32\n",
    "\n",
    "def load_image(path):\n",
    "    img = np.expand_dims(cv2.resize(cv2.imread(path, 0), (x_size, y_size)), axis=2)\n",
    "    return img\n",
    "\n",
    "def show_image(caption, img, destroy=True, show=True, wait_ms=1000):\n",
    "    if not show: return\n",
    "    cv2.imshow(caption, img)\n",
    "    cv2.waitKey(wait_ms)\n",
    "    if destroy: cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "719eb033efc7276e",
   "metadata": {},
   "source": [
    "# **Creating and Loading the model**"
   ]
  },
  {
   "cell_type": "code",
   "id": "bbd782df14f91036",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T09:21:12.581262Z",
     "start_time": "2025-08-18T09:21:12.413576Z"
    }
   },
   "source": [
    "model = model\n",
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "\n",
    "model = load_model(\"best_accuracy_model.keras\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "1e281f80fa028c58",
   "metadata": {},
   "source": [
    "# **Preprocessing new image function**"
   ]
  },
  {
   "cell_type": "code",
   "id": "55fa5d48f88e7e64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T09:21:12.608662Z",
     "start_time": "2025-08-18T09:21:12.590312Z"
    }
   },
   "source": [
    "def load_image(path, show_process=True):\n",
    "    image = cv2.imread(path)\n",
    "    # Base image\n",
    "    show_image(caption=\"Original image\", img=image, show=show_process)\n",
    "    original_img = image.copy()\n",
    "\n",
    "    # Bitwise, Gray scale, Blur\n",
    "    min_ffill_count = 50  # Filtering noise\n",
    "    number_str = \"\"\n",
    "    img_base = cv2.bitwise_not(image)\n",
    "    img_gray = cv2.cvtColor(img_base, cv2.COLOR_BGR2GRAY)\n",
    "    img_blurred = cv2.blur(img_gray, ksize=(5, 5))\n",
    "    show_image(\"Blurred image\", img=img_blurred, show=show_process)\n",
    "\n",
    "    # Binary image\n",
    "    _, binay_img = cv2.threshold(img_blurred, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    show_image(\"Binary image\", img=binay_img, show=show_process)\n",
    "\n",
    "    # Rotate the binary image\n",
    "    rotated_binary_img = cv2.rotate(binay_img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    show_image(caption=\"Rotated binary image\", img=rotated_binary_img, show=show_process)\n",
    "\n",
    "    # Height of rotated image\n",
    "    height = rotated_binary_img.shape[0]\n",
    "\n",
    "    # Create a copy for processing\n",
    "    processed_img = rotated_binary_img.copy()\n",
    "\n",
    "    # Finding the number character\n",
    "    for x in range(height):\n",
    "        # Check if there are any white pixels left in the image\n",
    "        if np.max(processed_img) == 0:\n",
    "            break  \n",
    "\n",
    "        # Check entire row for white pixels\n",
    "        text_pixel = np.where(processed_img[x, :] == 255)[0]\n",
    "        if text_pixel.size > 0:\n",
    "            y = (text_pixel[0])\n",
    "            img_ffill = processed_img.copy()\n",
    "\n",
    "            # Flood Fill\n",
    "            ffill_count, ffill_img, ffill_mask, ffill_rect = cv2.floodFill(img_ffill, mask=None, seedPoint=(y, x), newVal=64)\n",
    "            # ffill_count, ffill_img, ffill_mask, ffill_rect = cv2.floodFill(img_ffill, mask=None, seedPoint=(y, x), newVal=0)\n",
    "            show_image(\"Current digit:\", img_ffill, destroy=False, show=show_process)\n",
    "\n",
    "            img_diff = processed_img - img_ffill\n",
    "            img_diff[img_diff != 0] = 255\n",
    "            show_image(\"Current digit:\", img_diff, destroy=False, show=show_process)\n",
    "\n",
    "            # Extract the digit using the bounding rectangle\n",
    "            x1, y1, w, h = ffill_rect\n",
    "            img_digit = img_diff[y1:y1+h, x1:x1+w]\n",
    "            img_digit = cv2.rotate(img_digit, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "            # Skip if the digit is too small (likely noise)\n",
    "            if w < 5 or h < 5:\n",
    "                continue\n",
    "\n",
    "            img_digit_resized = np.array([cv2.resize(img_digit, (x_size, y_size))]) / 255\n",
    "            img_digit_resized = np.expand_dims(img_digit_resized, axis=3)\n",
    "\n",
    "            # Predicting the number of image\n",
    "            predicted = model.predict(img_digit_resized)\n",
    "            y_predicted = np.argmax(predicted[0])\n",
    "            print(f\"Predict: {y_predicted}\")\n",
    "\n",
    "            if ffill_count > min_ffill_count:\n",
    "                number_str += str(y_predicted)\n",
    "\n",
    "            show_image(\"Current digit: \", img_digit, destroy=False, show=show_process)\n",
    "\n",
    "            # Remove the detected digit from the processed image\n",
    "            processed_img[y1:y1+h, x1:x1+w] = 0\n",
    "\n",
    "    # Create a white strip at the bottom of the original image\n",
    "    height_strip = 50\n",
    "    # Create a white strip with the same width as the image and 3 channels (RGB)\n",
    "    white_strip = np.ones((height_strip, original_img.shape[1], 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # Concatenate the original image and the white strip vertically\n",
    "    result_img = np.vstack([original_img, white_strip])\n",
    "\n",
    "    # Add text to the result image\n",
    "    cv2.putText(result_img, \"Number:-\" + number_str, org=(10, result_img.shape[0] - 15),\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 0, 0), lineType=cv2.LINE_AA)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    show_image(\"Final digit\", result_img, show=show_process)\n",
    "    print(number_str)\n",
    "    return (number_str, result_img)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "e7fd032216c0ab48",
   "metadata": {},
   "source": [
    "# **GUI**"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7cf8152221ad16d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T09:21:12.625220Z",
     "start_time": "2025-08-18T09:21:12.617312Z"
    }
   },
   "source": [
    "def open_file_dialog():\n",
    "    # Define the supported file types\n",
    "    file_types = [(\"All image files\", \"*.png;*.jpg;*.bmp\"), (\"PNG Files\", \"*.png\"), (\"JPG Files\", \"*.jpg\"), (\"BMP Files\", \"*.bmp\")]\n",
    "\n",
    "    # Open file dialog\n",
    "    file_path = tk.filedialog.askopenfilename(filetypes=file_types)\n",
    "\n",
    "    # Check if a file was selected\n",
    "    if file_path:\n",
    "        # Update status label to indicate processing is in progress\n",
    "        lbl_no.config(text=\"Working...\")\n",
    "        root.update()  # Force GUI update to show the status immediately\n",
    "\n",
    "        # Get checkbox value (1 if checked, 0 if unchecked) to determine if processing steps should be shown\n",
    "        show_process = chk_var.get() == 1\n",
    "\n",
    "        # Call the image processing function to recognize numbers in the image\n",
    "        # Returns: (recognized_number_string, result_image_with_text)\n",
    "        the_no, the_img = load_image(file_path, show_process=show_process)\n",
    "\n",
    "        # Update the label to show the recognized number\n",
    "        lbl_no.config(text=\"The number is: \" + the_no)\n",
    "\n",
    "        # Convert image color\n",
    "        the_img = cv2.cvtColor(the_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Convert NumPy array to PIL Image object\n",
    "        img_pil = Image.fromarray(the_img)\n",
    "\n",
    "        # Convert PIL Image to Tkinter-compatible PhotoImage\n",
    "        img_tk = ImageTk.PhotoImage(img_pil)\n",
    "\n",
    "        # Update the image label to display the result image\n",
    "        lbl_img.config(image=img_tk)\n",
    "        # Keep a reference to prevent garbage collection\n",
    "        lbl_img.image = img_tk"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "d65430d196f410ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T09:21:54.805642Z",
     "start_time": "2025-08-18T09:21:12.634230Z"
    }
   },
   "source": [
    "# Main application window\n",
    "root = tk.Tk()\n",
    "# Set the window title\n",
    "root.title(\"Number reader\")\n",
    "\n",
    "# Get the screen dimensions\n",
    "screen_width = root.winfo_screenwidth()  # Width of the screen\n",
    "screen_height = root.winfo_screenheight()  # Height of the screen\n",
    "\n",
    "# Define the desired window dimensions\n",
    "window_width = 860\n",
    "window_height = 640\n",
    "\n",
    "# Calculate the x and y coordinates to center the window\n",
    "x_coordinate = int((screen_width / 2) - (window_width / 2))  # Center horizontally\n",
    "y_coordinate = int((screen_height / 2) - (window_height / 2))  # Center vertically\n",
    "\n",
    "# Set the window geometry\n",
    "root.geometry(f\"{window_width}x{window_height}+{x_coordinate}+{y_coordinate}\")\n",
    "\n",
    "# Create a button to load images\n",
    "btn_load = tk.Button(root, text=\"Load image\", command=open_file_dialog)\n",
    "# Pack the button in the window\n",
    "btn_load.pack(anchor=\"center\", pady=10)\n",
    "\n",
    "# Create an integer variable to store the checkbox state\n",
    "chk_var = tk.IntVar()\n",
    "# Create a checkbox\n",
    "chk_show = tk.Checkbutton(root, text=\"Show process\", variable=chk_var)\n",
    "# Pack the checkbox\n",
    "chk_show.pack()\n",
    "# Set the checkbox to checked by default (value 1)\n",
    "chk_var.set(1)\n",
    "\n",
    "# Create a label to display the recognized number\n",
    "lbl_no = tk.Label(root, text=\"\")\n",
    "# Pack the label\n",
    "lbl_no.pack(anchor=\"center\", pady=10)\n",
    "\n",
    "# Create a label to display the processed image\n",
    "lbl_img = tk.Label(root)\n",
    "# Pack the label\n",
    "lbl_img.pack(anchor=\"center\", pady=10)\n",
    "\n",
    "# Start the Tkinter event loop to display\n",
    "root.mainloop()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 127ms/step\n",
      "Predict: 0\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "Predict: 1\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "Predict: 2\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "Predict: 3\n",
      "0123\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "Predict: 3\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "Predict: 8\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "Predict: 2\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "Predict: 4\n",
      "3824\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
