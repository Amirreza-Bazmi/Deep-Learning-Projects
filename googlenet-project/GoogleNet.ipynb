{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-B0uA_xBtCC",
        "outputId": "53bd1cba-c48a-47b7-c9ce-0dce92280d7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:02<00:00, 22736.25it/s]\n",
            "100%|██████████| 10000/10000 [00:00<00:00, 31399.24it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar100\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Flatten\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "from skimage.transform import resize\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import gc\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    precision_val = precision(y_true, y_pred)\n",
        "    recall_val = recall(y_true, y_pred)\n",
        "    return 2*((precision_val*recall_val)/(precision_val+recall_val+K.epsilon()))\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Resize images to meet InceptionV3 input size requirements (75x75)\n",
        "train_resized_imgs = []\n",
        "for img in tqdm(x_train):\n",
        "   resized = cv2.resize(img,(75,75))\n",
        "   train_resized_imgs.append(resized)\n",
        "train_resized_imgs = np.array(train_resized_imgs)\n",
        "x_train = train_resized_imgs\n",
        "\n",
        "\n",
        "test_resized_imgs = []\n",
        "for img in tqdm(x_test):\n",
        "   resized = cv2.resize(img,(75,75))\n",
        "   test_resized_imgs.append(resized)\n",
        "test_resized_imgs = np.array(test_resized_imgs)\n",
        "x_test = test_resized_imgs\n",
        "\n",
        "del train_resized_imgs\n",
        "del test_resized_imgs\n",
        "gc.collect()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = preprocess_input(x_train)\n",
        "x_test = preprocess_input(x_test)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V-pvNdxGTgr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "742d9752-82e4-4daf-cd00-a8f728feb449"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'InceptionV3' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9d60adcfff50>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load pre-trained InceptionV3 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInceptionV3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Freeze layers of the pre-trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'InceptionV3' is not defined"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "epochs = 30\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "\n",
        "# Load pre-trained InceptionV3 model\n",
        "base_model = InceptionV3(weights= \"imagenet\", include_top=False, input_shape=(75, 75, 3))\n",
        "\n",
        "# Freeze layers of the pre-trained model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of pre-trained model\n",
        "x = base_model.output\n",
        "# x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
        "# x = Flatten()(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(100, activation='softmax')(x)\n",
        "\n",
        "# Combine base model and custom layers into a new model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "# Compile the model with custom metrics\n",
        "model.compile(optimizer=SGD(learning_rate=learning_rate, momentum= momentum),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', recall, precision, f1])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training and Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Epochs: 30     Learning Rate: 0.01     Momentum: 0.9    Batch size: 128**"
      ],
      "metadata": {
        "id": "GWya89tuXxF9"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}